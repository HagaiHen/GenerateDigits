import torch
from config import get_device, batch_size, lr
from torch import nn
import matplotlib.pyplot as plt
import torchvision
import torchvision.transforms as transforms
from train import trainer
from Discriminator import Discriminator
from Generator import Generator

# Get the available device
device = get_device()

# Set a seed
torch.manual_seed(7)

# Compose the transformation
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])

# Load the training set
train_set = torchvision.datasets.MNIST(root=".", train=True, download=True, transform=transform)
train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)

# Show samples from the dataset
real_samples, mnist_labels = next(iter(train_loader))
for i in range(16):
    ax = plt.subplot(4, 4, i + 1)
    plt.imshow(real_samples[i].reshape(28, 28), cmap="gray_r")
    plt.xticks([])
    plt.yticks([])

# Display the plot
plt.show()

# Initialize the generator and discriminator
generator = Generator().to(device=device)
discriminator = Discriminator().to(device=device)

# Define the loss function
loss_function = nn.BCELoss()

# Define the optimizers
optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)
optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)

# Train the GAN
trainer(train_loader, generator, discriminator, loss_function, optimizer_discriminator, optimizer_generator, device)

# Show samples generated by the generator
latent_space_samples = torch.randn(batch_size, 100).to(device=device)
generated_samples = generator(latent_space_samples)

# Move the generated samples to the CPU and detach from the computation graph
generated_samples = generated_samples.cpu().detach()
for i in range(16):
    ax = plt.subplot(4, 4, i + 1)
    plt.imshow(generated_samples[i].reshape(28, 28), cmap="gray_r")
    plt.xticks([])
    plt.yticks([])

# Display the plot
plt.show()